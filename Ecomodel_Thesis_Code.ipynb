{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do small habitat patches support higher biodiversity for an equivalent habitat area?\n",
    "\n",
    "Erin Ricaloglu, Jurek Kolasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting through the CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the directory where your CSV files are stored\n",
    "directory_path = 'xxx'  \n",
    "\n",
    "## NetLogo, has a code that will store a CSV file following each simulation run, with a designated location. This is outlined in the Code, within the application, and must be altered to each individual's desktop. \n",
    "\n",
    "# Load each CSV file into a DataFrame and append to the list\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):  # Only process CSV files\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Clean up column names by stripping extra spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Ensure the 'Year' column is numeric\n",
    "combined_data['Year'] = pd.to_numeric(combined_data['Year'], errors='coerce')\n",
    "combined_data = combined_data.dropna(subset=['Year'])\n",
    "combined_data['Year'] = combined_data['Year'].astype(int)\n",
    "\n",
    "# Ensure 'Type A Count' and 'Type B Count' are numeric\n",
    "combined_data['Type A Count'] = pd.to_numeric(combined_data['Type A Count'], errors='coerce').fillna(0)\n",
    "combined_data['Type B Count'] = pd.to_numeric(combined_data['Type B Count'], errors='coerce').fillna(0)\n",
    "\n",
    "# Sort data by Year and Patch for proper calculations\n",
    "combined_data.sort_values(by=['Patch X', 'Patch Y', 'Year'], inplace=True)\n",
    "\n",
    "# Calculate turnover for Type A (Specialists) and Type B (Generalists) per patch\n",
    "combined_data['Type A Turnover'] = combined_data.groupby(['Patch X', 'Patch Y'])['Type A Count'].diff().abs().fillna(0)\n",
    "combined_data['Type B Turnover'] = combined_data.groupby(['Patch X', 'Patch Y'])['Type B Count'].diff().abs().fillna(0)\n",
    "\n",
    "# Group by Year to calculate the mean turnover per year for specialists and generalists\n",
    "mean_turnover_per_year = combined_data.groupby('Year').agg({\n",
    "    'Type A Turnover': 'mean',\n",
    "    'Type B Turnover': 'mean'\n",
    "})\n",
    "\n",
    "# Function to convert string representation of a list to an actual list\n",
    "def parse_list_from_string(string):\n",
    "    try:\n",
    "        # Remove brackets, quotes, and any extra spaces or characters\n",
    "        cleaned_string = string.strip('[]').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        # Split by comma and further clean each item\n",
    "        items = cleaned_string.split(',')\n",
    "        parsed_list = [item.strip() for item in items if item.strip()]\n",
    "        return parsed_list\n",
    "    except Exception as e:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Species Turnover, for compositional change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean species turnover over time for specialists and generalists\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mean_turnover_per_year.index, mean_turnover_per_year['Type A Turnover'], \n",
    "         marker='o', color='blue', linestyle='-', label='Mean Specialist Turnover')\n",
    "\n",
    "plt.plot(mean_turnover_per_year.index, mean_turnover_per_year['Type B Turnover'], \n",
    "         marker='s', color='green', linestyle='-', label='Mean Generalist Turnover')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Species Turnover')\n",
    "plt.title('Mean Specialist vs. Generalist Turnover Over Time in Small Patches')\n",
    "plt.legend()\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Species Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string representation of a list to an actual list\n",
    "def parse_list_from_string(string):\n",
    "    try:\n",
    "        cleaned_string = string.strip('[]').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        items = cleaned_string.split(',')\n",
    "        parsed_list = [item.strip() for item in items if item.strip()]\n",
    "        return parsed_list\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "# Function to extract unique species from 'Current Species List'\n",
    "def extract_species(species_list_str):\n",
    "    species_list = parse_list_from_string(species_list_str)\n",
    "    return set(species_list)  # Return as a set for uniqueness\n",
    "\n",
    "# Apply the function to extract species per patch\n",
    "df[\"Unique Species\"] = df[\"Current Species List\"].apply(extract_species)\n",
    "\n",
    "# Separate species richness for specialists (Type A) and generalists (Type B)\n",
    "df[\"Unique Specialist Species\"] = df.apply(lambda row: set(row[\"Unique Species\"]) if row[\"Type A Count\"] > 0 else set(), axis=1)\n",
    "df[\"Unique Generalist Species\"] = df.apply(lambda row: set(row[\"Unique Species\"]) if row[\"Type B Count\"] > 0 else set(), axis=1)\n",
    "\n",
    "# Group by 'Year' and calculate species richness (number of unique species per year)\n",
    "specialist_richness_per_year = df.groupby(\"Year\")[\"Unique Specialist Species\"].apply(lambda species_sets: len(set().union(*species_sets)))\n",
    "generalist_richness_per_year = df.groupby(\"Year\")[\"Unique Generalist Species\"].apply(lambda species_sets: len(set().union(*species_sets)))\n",
    "\n",
    "# Plot specialist vs generalist species richness over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(specialist_richness_per_year.index, specialist_richness_per_year.values, marker=\"o\", color=\"blue\", linestyle=\"-\", label=\"Specialist Species Richness\")\n",
    "plt.plot(generalist_richness_per_year.index, generalist_richness_per_year.values, marker=\"s\", color=\"green\", linestyle=\"-\", label=\"Generalist Species Richness\")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Unique Species (Richness)\")\n",
    "plt.title(\"Specialist vs Generalist Species Richness Over Time in Small Patches\")\n",
    "plt.legend()\n",
    "plt.grid(visible=True, linestyle=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section will display numerical metrics, in regards to the loaded dataframe. Typically for an entire experiment and singular patch size. Ex. 30 runs and Small Patches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean CSV Files\n",
    "def load_and_clean_data(folder_path):\n",
    "    df_list = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "            df.columns = df.columns.str.strip()  # Clean column names\n",
    "            \n",
    "            # Convert list-like strings into actual lists\n",
    "            if \"Current Species List\" in df.columns:\n",
    "                df[\"Current Species List\"] = df[\"Current Species List\"].apply(parse_list_from_string)\n",
    "            \n",
    "            df_list.append(df)\n",
    "\n",
    "    df_combined = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Print available columns for debugging\n",
    "    print(\"\\nAvailable columns in dataset:\", df_combined.columns.tolist())\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "# Convert String Representation of Lists\n",
    "def parse_list_from_string(string):\n",
    "    if isinstance(string, str):\n",
    "        cleaned_string = string.strip('[]').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        items = cleaned_string.split(',')\n",
    "        return [item.strip() for item in items if item.strip()]\n",
    "    return string\n",
    "\n",
    "# Calculate Alpha Diversity (Species Richness per Patch)\n",
    "def calculate_alpha_diversity(df):\n",
    "    if \"Current Species List\" in df.columns:\n",
    "        df[\"Species_Richness\"] = df[\"Current Species List\"].apply(len)\n",
    "        return df.groupby([\"Patch X\", \"Patch Y\"])[\"Species_Richness\"].mean()\n",
    "    else:\n",
    "        print(\"\\nSkipping Alpha Diversity: 'Current Species List' column missing.\")\n",
    "        return None\n",
    "\n",
    "# Calculate Gamma Diversity (Total Species Richness)\n",
    "def calculate_gamma_diversity(df):\n",
    "    if \"Current Species List\" in df.columns:\n",
    "        all_species = set(species for sublist in df[\"Current Species List\"] for species in sublist)\n",
    "        return len(all_species)\n",
    "    else:\n",
    "        print(\"\\nSkipping Gamma Diversity: 'Current Species List' column missing.\")\n",
    "        return None\n",
    "\n",
    "# Calculate Turnover Percentage\n",
    "def calculate_turnover_percentage(df):\n",
    "    if \"Turnover\" in df.columns:\n",
    "        df[\"Turnover_Percentage\"] = (df[\"Turnover\"] / df[\"Turnover\"].sum()) * 100\n",
    "    return df\n",
    "\n",
    "\n",
    "# Perform ANOVA (Differences in Species Richness Across Patch Suitability)\n",
    "def perform_anova(df):\n",
    "    if \"Patch Suitability\" in df.columns and \"Species_Richness\" in df.columns:\n",
    "        anova_result = f_oneway(\n",
    "            df[df[\"Patch Suitability\"] < df[\"Patch Suitability\"].quantile(0.33)][\"Species_Richness\"],\n",
    "            df[df[\"Patch Suitability\"].between(df[\"Patch Suitability\"].quantile(0.33), df[\"Patch Suitability\"].quantile(0.66))][\"Species_Richness\"],\n",
    "            df[df[\"Patch Suitability\"] > df[\"Patch Suitability\"].quantile(0.66)][\"Species_Richness\"]\n",
    "        )\n",
    "        print(\"\\nANOVA Results for Species Richness by Patch Suitability:\", anova_result)\n",
    "        return anova_result\n",
    "    else:\n",
    "        print(\"\\nSkipping ANOVA: Required columns missing.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Calculate Coefficient of Variation (CV)\n",
    "def coefficient_of_variation(series):\n",
    "    return (np.std(series) / np.mean(series)) * 100 if np.mean(series) != 0 else 0\n",
    "\n",
    "def calculate_coefficient_of_variation(df):\n",
    "    if \"Species_Richness\" in df.columns and \"Turnover\" in df.columns:\n",
    "        cv_species_richness = coefficient_of_variation(df[\"Species_Richness\"])\n",
    "        cv_turnover = coefficient_of_variation(df[\"Turnover\"])\n",
    "        print(\"\\nCoefficient of Variation (Species Richness):\", cv_species_richness)\n",
    "        print(\"Coefficient of Variation (Turnover):\", cv_turnover)\n",
    "        return cv_species_richness, cv_turnover\n",
    "    else:\n",
    "        print(\"\\nSkipping CV Calculation: Required columns missing.\")\n",
    "        return None, None\n",
    "\n",
    "# Main Execution Function\n",
    "def main(folder_path):\n",
    "    # Load and clean data\n",
    "    df = load_and_clean_data(folder_path)\n",
    "\n",
    "    # Compute Metrics\n",
    "    alpha_diversity = calculate_alpha_diversity(df)\n",
    "    gamma_diversity = calculate_gamma_diversity(df)\n",
    "    df = calculate_turnover_percentage(df)\n",
    "\n",
    "    # Perform Statistical Analyses\n",
    "    anova_result = perform_anova(df)\n",
    "    cv_species_richness, cv_turnover = calculate_coefficient_of_variation(df)\n",
    "\n",
    "    # Print key metrics\n",
    "    if alpha_diversity is not None:\n",
    "        print(\"\\nAlpha Diversity (Mean Species Richness per Patch):\")\n",
    "        print(alpha_diversity)\n",
    "    if gamma_diversity is not None:\n",
    "        print(\"\\nGamma Diversity (Total Species Richness Across All Patches):\", gamma_diversity)\n",
    "\n",
    "# Run the script with folder path\n",
    "folder_path = \"\"  # Replace with actual path\n",
    "main(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Bray-Curtis Dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=bray_curtis_df, x=\"Bray-Curtis Dissimilarity\", binwidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turnover Stability Trends: Comparisons for Multiple Patch Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the two different directories (For ex. Small and Large Patch sizes, 30 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "small_patch_dir = ''\n",
    "large_patch_dir = ''\n",
    "\n",
    "# Function to load and concatenate CSVs\n",
    "def load_data(directory):\n",
    "    df_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df.columns = df.columns.str.strip()  # Ensure clean column names\n",
    "            df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True) if df_list else None\n",
    "\n",
    "# Load small and large patch data\n",
    "df_small = load_data(small_patch_dir)\n",
    "df_large = load_data(large_patch_dir)\n",
    "\n",
    "# Check if data loaded correctly\n",
    "if df_small is None or df_large is None:\n",
    "    print(\"Error loading data. Check directory paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further CSV cleanup, to ensure files are read correctly. Further, year 1 is removed, as only years 2-5 are analyzed in the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing spaces from column names\n",
    "df_small.columns = df_small.columns.str.strip()\n",
    "df_large.columns = df_large.columns.str.strip()\n",
    "\n",
    "# Check again after cleaning\n",
    "print(\"Cleaned Small Patch Dataset Columns:\", df_small.columns)\n",
    "print(\"Cleaned Large Patch Dataset Columns:\", df_large.columns)\n",
    "\n",
    "# Now you can select the columns safely\n",
    "selected_columns = ['Turnover', 'Type A Count', 'Type B Count', 'Total Species']\n",
    "df_small = df_small[selected_columns]\n",
    "df_large = df_large[selected_columns]\n",
    "\n",
    "# Strip spaces from column names\n",
    "df_small.columns = df_small.columns.str.strip()\n",
    "df_large.columns = df_large.columns.str.strip()\n",
    "\n",
    "# Ensure 'Year' column is numeric\n",
    "df_small[\"Year\"] = df_small[\"Year\"].astype(int)\n",
    "df_large[\"Year\"] = df_large[\"Year\"].astype(int)\n",
    "\n",
    "# Filter data: Keep only Years 2-5\n",
    "df_small_filtered = df_small[df_small[\"Year\"].between(2, 5)]\n",
    "df_large_filtered = df_large[df_large[\"Year\"].between(2, 5)]\n",
    "\n",
    "# Group by Year to calculate mean turnover\n",
    "small_turnover = df_small_filtered.groupby(\"Year\")[\"Turnover\"].mean()\n",
    "large_turnover = df_large_filtered.groupby(\"Year\")[\"Turnover\"].mean()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Line plots for turnover trends\n",
    "sns.lineplot(x=small_turnover.index, y=small_turnover, label=\"Small Patches\", color=\"blue\", linewidth=2)\n",
    "sns.lineplot(x=large_turnover.index, y=large_turnover, label=\"Large Patches\", color=\"red\", linewidth=2)\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel(\"Time (Years)\", fontsize=14)\n",
    "plt.ylabel(\"Mean Turnover\", fontsize=14)\n",
    "plt.title(\"Turnover Stability Trends Over Time (Years 2-5)\", fontsize=16, fontweight=\"bold\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Serif\"  # Elegant and readable\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Final Figures:\n",
    "\n",
    "Figure 1: Scatter plots with polynomial regression lines depicting the relationship between total patch density (N) and species richness for specialists (red) and generalists (blue) in large (top row) and small (bottom row) patches. Top Left: In large patches, specialist richness follows a weak unimodal trend, peaking at intermediate densities before declining (R² = 0.41). Top Right: Generalist richness in large patches increases with total density, showing a strong positive correlation (R² = 0.70). Bottom Left: In small patches, specialist richness exhibits a clearer unimodal trend, increasing initially but declining at high densities, indicating possible competition effects (R² = 0.82). Bottom Right: Generalist richness in small patches increases sharply with total patch density, following an exponential-like trend (R² = 0.86). \n",
    "\n",
    "Figure 2: Created in Statistica. \n",
    "\n",
    "\n",
    "Figure 3: Temporal changes in generalist and specialist richness (black lines) and species turnover (red dashed lines) in large and small habitat patches from Years 2 to 5. Top Left: Generalist richness and Turnover in Large Patches. Top Right: Specialist richness and turnover in Large Patches.  Bottom Left: Generalist richness and turnover in Small Patches.  Bottom Right: Specialist richness with turnover in Small Patches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Strip spaces from column names\n",
    "df_small.columns = df_small.columns.str.strip()\n",
    "df_large.columns = df_large.columns.str.strip()\n",
    "\n",
    "# Convert necessary columns to numeric\n",
    "numeric_cols = [\"Type A Count\", \"Type B Count\", \"Patch Density\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df_small[col] = pd.to_numeric(df_small[col], errors=\"coerce\")\n",
    "    df_large[col] = pd.to_numeric(df_large[col], errors=\"coerce\")\n",
    "\n",
    "# Filter data: Keep only Years 2-5\n",
    "df_small_filtered = df_small[df_small[\"Year\"].between(2, 5)]\n",
    "df_large_filtered = df_large[df_large[\"Year\"].between(2, 5)]\n",
    "\n",
    "# Group by total patch density and compute mean richness\n",
    "df_small_grouped = df_small_filtered.groupby(\"Patch Density\")[[\"Type A Count\", \"Type B Count\"]].mean().reset_index()\n",
    "df_large_grouped = df_large_filtered.groupby(\"Patch Density\")[[\"Type A Count\", \"Type B Count\"]].mean().reset_index()\n",
    "\n",
    "# Function to fit and plot polynomial regression with R² value in legend\n",
    "def plot_polynomial_regression(ax, x_data, y_data, color, label):\n",
    "    \"\"\"Fits a quadratic regression model and plots with R² value in the legend.\"\"\"\n",
    "    x_data = x_data.values.reshape(-1, 1)\n",
    "    y_data = y_data.values\n",
    "\n",
    "    # Create polynomial features (quadratic)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly.fit_transform(x_data)\n",
    "\n",
    "    # Fit polynomial regression model\n",
    "    model = LinearRegression().fit(x_poly, y_data)\n",
    "    y_pred = model.predict(x_poly)\n",
    "    \n",
    "    # Calculate R² value\n",
    "    r2 = r2_score(y_data, y_pred)\n",
    "    \n",
    "    # Sort x values for smooth plotting\n",
    "    sorted_indices = np.argsort(x_data.flatten())\n",
    "    x_sorted = x_data.flatten()[sorted_indices]\n",
    "    y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "    # Plot scatter and regression line\n",
    "    ax.scatter(x_data, y_data, color=color, s=50, alpha=0.6, label=f\"{label} Data\")\n",
    "    ax.plot(x_sorted, y_pred_sorted, linestyle=\"dashed\", linewidth=2, color=color, \n",
    "            label=f\"{label} Fit (R²={r2:.2f})\")\n",
    "\n",
    "    # Remove gridlines\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Add legend to each subplot\n",
    "    ax.legend(fontsize=10, loc=\"upper left\")\n",
    "\n",
    "    return r2\n",
    "\n",
    "# Create figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "### **Large Patches: Specialist Richness vs. Total Density**\n",
    "plot_polynomial_regression(axes[0, 0], df_large_grouped[\"Patch Density\"], df_large_grouped[\"Type A Count\"], \"red\", \"Specialist\")\n",
    "axes[0, 0].set_title(\"Large Patches - Specialist Richness vs. Total Density\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].set_xlabel(\"Total Patch Density (N)\", fontsize=12)\n",
    "axes[0, 0].set_ylabel(\"Specialist Richness\", fontsize=12)\n",
    "\n",
    "### **Large Patches: Generalist Richness vs. Total Density**\n",
    "plot_polynomial_regression(axes[0, 1], df_large_grouped[\"Patch Density\"], df_large_grouped[\"Type B Count\"], \"blue\", \"Generalist\")\n",
    "axes[0, 1].set_title(\"Large Patches - Generalist Richness vs. Total Density\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].set_xlabel(\"Total Patch Density (N)\", fontsize=12)\n",
    "axes[0, 1].set_ylabel(\"Generalist Richness\", fontsize=12)\n",
    "\n",
    "### **Small Patches: Specialist Richness vs. Total Density**\n",
    "plot_polynomial_regression(axes[1, 0], df_small_grouped[\"Patch Density\"], df_small_grouped[\"Type A Count\"], \"red\", \"Specialist\")\n",
    "axes[1, 0].set_title(\"Small Patches - Specialist Richness vs. Total Density\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 0].set_xlabel(\"Total Patch Density (N)\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Specialist Richness\", fontsize=12)\n",
    "\n",
    "### **Small Patches: Generalist Richness vs. Total Density**\n",
    "plot_polynomial_regression(axes[1, 1], df_small_grouped[\"Patch Density\"], df_small_grouped[\"Type B Count\"], \"blue\", \"Generalist\")\n",
    "axes[1, 1].set_title(\"Small Patches - Generalist Richness vs. Total Density\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xlabel(\"Total Patch Density (N)\", fontsize=12)\n",
    "axes[1, 1].set_ylabel(\"Generalist Richness\", fontsize=12)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"poly_regression.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style and font preferences\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Serif\"  # Use a readable serif font\n",
    "\n",
    "# Ensure numerical columns are properly formatted\n",
    "numeric_cols = [\"Turnover\", \"Type A Count\", \"Type B Count\"]\n",
    "\n",
    "# Convert columns to numeric\n",
    "for col in numeric_cols:\n",
    "    df_small[col] = pd.to_numeric(df_small[col], errors=\"coerce\")\n",
    "    df_large[col] = pd.to_numeric(df_large[col], errors=\"coerce\")\n",
    "\n",
    "# Filter Data for Years 2-5\n",
    "df_small_filtered = df_small[(df_small[\"Year\"] >= 2) & (df_small[\"Year\"] <= 5)]\n",
    "df_large_filtered = df_large[(df_large[\"Year\"] >= 2) & (df_large[\"Year\"] <= 5)]\n",
    "\n",
    "# Group by year and compute mean richness & turnover\n",
    "df_large_grouped = df_large_filtered.groupby(\"Year\")[numeric_cols].mean()\n",
    "df_small_grouped = df_small_filtered.groupby(\"Year\")[numeric_cols].mean()\n",
    "\n",
    "# Find y-axis limits for large patches\n",
    "large_y_min, large_y_max = df_large_grouped.min().min(), df_large_grouped.max().max()\n",
    "\n",
    "# Find y-axis limits for small patches (smaller range for clarity)\n",
    "small_y_min, small_y_max = df_small_grouped.min().min(), df_small_grouped.max().max() * 1.2  \n",
    "\n",
    "# Create the figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Define line properties\n",
    "line_styles = {\"Turnover\": {\"color\": \"red\", \"marker\": \"o\", \"linestyle\": \"--\"},\n",
    "               \"Type A Count\": {\"color\": \"black\", \"marker\": \"s\", \"linestyle\": \"-\"},\n",
    "               \"Type B Count\": {\"color\": \"black\", \"marker\": \"^\", \"linestyle\": \"-\"}}\n",
    "\n",
    "# Large Patches - Generalist Richness vs. Turnover\n",
    "sns.lineplot(x=df_large_grouped.index, y=df_large_grouped[\"Turnover\"], \n",
    "             **line_styles[\"Turnover\"], label=\"Turnover\", ax=axes[0, 0])\n",
    "sns.lineplot(x=df_large_grouped.index, y=df_large_grouped[\"Type B Count\"], \n",
    "             **line_styles[\"Type B Count\"], label=\"Generalist Richness\", ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Large Patches - Generalist Richness vs. Turnover\", fontsize=15, fontweight=\"bold\")\n",
    "axes[0, 0].set_xlabel(\"Year\", fontsize=13)\n",
    "axes[0, 0].tick_params(axis=\"both\", labelsize=12)\n",
    "axes[0, 0].set_ylim(large_y_min, large_y_max)\n",
    "axes[0, 0].legend(fontsize=12, frameon=True)\n",
    "\n",
    "# Large Patches - Specialist Richness vs. Turnover\n",
    "sns.lineplot(x=df_large_grouped.index, y=df_large_grouped[\"Turnover\"], \n",
    "             **line_styles[\"Turnover\"], label=\"Turnover\", ax=axes[0, 1])\n",
    "sns.lineplot(x=df_large_grouped.index, y=df_large_grouped[\"Type A Count\"], \n",
    "             **line_styles[\"Type A Count\"], label=\"Specialist Richness\", ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Large Patches - Specialist Richness vs. Turnover\", fontsize=15, fontweight=\"bold\")\n",
    "axes[0, 1].set_xlabel(\"Year\", fontsize=13)\n",
    "axes[0, 1].tick_params(axis=\"both\", labelsize=12)\n",
    "axes[0, 1].set_ylim(large_y_min, large_y_max)\n",
    "axes[0, 1].legend(fontsize=12, frameon=True)\n",
    "\n",
    "# Small Patches - Generalist Richness vs. Turnover (Zoomed Y-Axis)\n",
    "sns.lineplot(x=df_small_grouped.index, y=df_small_grouped[\"Turnover\"], \n",
    "             **line_styles[\"Turnover\"], label=\"Turnover\", ax=axes[1, 0])\n",
    "sns.lineplot(x=df_small_grouped.index, y=df_small_grouped[\"Type B Count\"], \n",
    "             **line_styles[\"Type B Count\"], label=\"Generalist Richness\", ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Small Patches - Generalist Richness vs. Turnover\", fontsize=15, fontweight=\"bold\")\n",
    "axes[1, 0].set_xlabel(\"Year\", fontsize=13)\n",
    "axes[1, 0].tick_params(axis=\"both\", labelsize=12)\n",
    "axes[1, 0].set_ylim(small_y_min, small_y_max)  \n",
    "axes[1, 0].legend(fontsize=12, frameon=True)\n",
    "\n",
    "# Small Patches - Specialist Richness vs. Turnover (Zoomed Y-Axis)\n",
    "sns.lineplot(x=df_small_grouped.index, y=df_small_grouped[\"Turnover\"], \n",
    "             **line_styles[\"Turnover\"], label=\"Turnover\", ax=axes[1, 1])\n",
    "sns.lineplot(x=df_small_grouped.index, y=df_small_grouped[\"Type A Count\"], \n",
    "             **line_styles[\"Type A Count\"], label=\"Specialist Richness\", ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Small Patches - Specialist Richness vs. Turnover\", fontsize=15, fontweight=\"bold\")\n",
    "axes[1, 1].set_xlabel(\"Year\", fontsize=13)\n",
    "axes[1, 1].tick_params(axis=\"both\", labelsize=12)\n",
    "axes[1, 1].set_ylim(small_y_min, small_y_max)  \n",
    "axes[1, 1].legend(fontsize=12, frameon=True)\n",
    "\n",
    "# Apply the same y-axis label for all plots\n",
    "for ax in axes.flat:\n",
    "    ax.set_ylabel(\"Turnover and Species Count\", fontsize=13)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
